{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time zone: US/Eastern\n"
     ]
    }
   ],
   "source": [
    "from config import *\n",
    "import random\n",
    "from glob import glob\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm as tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import tensorflow as tf\n",
    "plt.rcParams['axes.grid'] = False\n",
    "# plt.rcParams['figure.figsize'] = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "In this notebook, we will be preprocessing our training data by applying several transformations to it that include color correction and resizing. \n",
    "\n",
    "## Table of Contents\n",
    "1. [Reading Image](#Reading-image)\n",
    "2. [Finding the Eye](#Finding-the-eye)\n",
    "3. [Color Correction](#Color-correction)\n",
    "4. [Image Resizing](#Image-resizing)\n",
    "5. [Putting it together](#Putting-it-together)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths, labels = {}, {}\n",
    "paths['aptos'] = {'train': glob(os.path.join(DATA_DIR, 'aptos', 'train', 'img', '*.png'))}\n",
    "paths['chf'] = {'train': glob(os.path.join(DATA_DIR,'chf' , 'train', 'img', '*.jpeg')),\n",
    "                'test': glob(os.path.join(DATA_DIR, 'chf', 'test', 'img', '*.jpeg'))}\n",
    "# paths['idrid'] = glob(os.path.join(DATA_DIR, 'idrid', 'grading', 'train', 'img', '*.jpg'))\n",
    "# paths['idrid'] += glob(os.path.join(DATA_DIR,'idrid', 'grading', 'test', 'img', '*.jpg'))\n",
    "labels['aptos'] = {'train': pd.read_csv(os.path.join(DATA_DIR, 'aptos', 'train', 'labels.csv')).sort_values(by='id')}\n",
    "labels['chf'] =  {'train': pd.read_csv(os.path.join(DATA_DIR, 'chf', 'train', 'labels.csv')).sort_values(by='id'), \n",
    "                  'test': pd.read_csv(os.path.join(DATA_DIR, 'chf', 'test', 'labels.csv')).sort_values(by='id')}\n",
    "for key in paths:\n",
    "    for split in paths[key]:\n",
    "        paths[key][split].sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is to read in the image :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the eye\n",
    "Finding the eye enables us to normalize over the different positioning variations in the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_eye(im):\n",
    "    cy = im.shape[0]//2\n",
    "    midline = im[cy,:]\n",
    "    midline = np.where(midline>midline.mean()/3)[0]\n",
    "    if len(midline)>im.shape[1]//2:\n",
    "        x_start, x_end = np.min(midline), np.max(midline)\n",
    "    else: # This actually rarely happens p~1/10000\n",
    "        x_start, x_end = im.shape[1]//10, 9*im.shape[1]//10\n",
    "    cx = (x_start + x_end)/2\n",
    "    r = (x_end - x_start)/2\n",
    "    return cx, cy, r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Color correction\n",
    "We will normalize the color across the images by subtracting median background color. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_median_bg_image(img):\n",
    "    k =np.max(img.shape)//20*2+1\n",
    "    bg = cv2.medianBlur(img, k)\n",
    "    return cv2.addWeighted(img, 4, bg, -4, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_correct(img):\n",
    "    h, w, _ = img.shape\n",
    "    sigmaX = min(h, w)/30\n",
    "    img = cv2.addWeighted(img, 4, cv2.GaussianBlur(img, (0,0), sigmaX), -4 ,128)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image resizing\n",
    "Since the images come in different sizes and aspect ratios, we will need to resize them to a fixed square image size. While doing so, however, we will avoid shrink/stretch effects by using padding and isolating the eye."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(img, size):\n",
    "    cx, cy, r = find_eye(img)\n",
    "    scaling = size/(2*r)\n",
    "    rotation = 0\n",
    "    M = cv2.getRotationMatrix2D((cx,cy), rotation, scaling)\n",
    "    M[0,2] -= cx - size/2\n",
    "    M[1,2] -= cy - size/2\n",
    "    return cv2.warpAffine(img,M,(size,size)) # This is the most important line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radius_reduce(img, param=96):\n",
    "    h,w,c=img.shape\n",
    "    Frame=np.zeros((h,w,c),dtype=np.uint8)\n",
    "    cv2.circle(Frame,(int(math.floor(w/2)),int(math.floor(h/2))),int(math.floor((h*param)/float(2*100))), (255,255,255), -1)\n",
    "    Frame1=cv2.cvtColor(Frame, cv2.COLOR_BGR2GRAY)\n",
    "    img1 =cv2.bitwise_and(img,img,mask=Frame1)\n",
    "    return img1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it together\n",
    "We are now ready to preprocess. We will use the concurrent module to utilise mutliple CPU cores on the computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 224\n",
    "per_chunk = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(path, size):\n",
    "    img = read_image(path)\n",
    "    img = resize_image(img, size)\n",
    "    img = subtract_median_bg_image(img)\n",
    "    img = radius_reduce(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the preprocessed images will be exported as tfrecords files, Tensorflow's reccomended binary file format. This means we will have to serialize the images, labels and ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize(img, label, _id):\n",
    "    feature = {\n",
    "        'img': bytes_feature(cv2.imencode('.jpg', img)[1].tostring()),\n",
    "        'diagnosis': int64_feature(label),\n",
    "        'id': bytes_feature(_id.encode())\n",
    "    }\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_serialize(d):\n",
    "    path, diagnosis, _id = d\n",
    "    img = preprocess(path, SIZE)\n",
    "    return serialize(img, diagnosis, _id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35126/35126 [00:00<00:00, 971366.65it/s]\n",
      "100%|██████████| 53576/53576 [00:00<00:00, 1087834.78it/s]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "# for ds in paths:\n",
    "ds = 'chf'\n",
    "for split in paths[ds]:\n",
    "    grades = np.asarray(labels[ds][split].diagnosis)\n",
    "    ids = np.asarray(labels[ds][split].id)\n",
    "    for i, path in enumerate(tqdm(paths[ds][split])):\n",
    "        data.append((path, grades[i], ids[i]))\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "serialized = []\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=4) as executor:\n",
    "    serialized = list(executor.map(preprocess_and_serialize, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chunks = int(np.ceil(len(serialized)/per_chunk))\n",
    "for i in range(num_chunks):\n",
    "    record_file = '{}_{:02d}.tfrecords'.format(ds, i)\n",
    "    with tf.io.TFRecordWriter(record_file) as writer:\n",
    "        for s in serialized[i*per_chunk : (i+1)*per_chunk]:\n",
    "            writer.write(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aptos",
   "language": "python",
   "name": "aptos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
